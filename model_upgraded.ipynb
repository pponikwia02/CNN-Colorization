{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798d52f8-ea13-45dc-ad4e-882cbf3f607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48cf5db-63fa-4ad1-9c55-4659db51b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=2137):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "DATA_PATH = 'data/landscape/'\n",
    "IMG_DIM =(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea805f33-e475-41de-afca-32384a1b5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(img_l,img_ab):\n",
    "    image=tf.concat([img_l,img_ab],axis=-1)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "    \n",
    "    image_l = image[..., :1]\n",
    "    image_ab = image[..., 1:]\n",
    "\n",
    "    return image_l, image_ab\n",
    "def create_dataset(X,y,batch_size=32, augmentation=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    if augmentation:\n",
    "        dataset = dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92de564c-6ba5-442e-97e9-72fb5798ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colorized_images(model, X_test, y_test=None, num_images=10):\n",
    "    indices = np.random.choice(len(X_test), num_images, replace=False)\n",
    "    plt.figure(figsize=(15, num_images * 3)) \n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img_l = X_test[idx][np.newaxis, ...]  \n",
    "        img_l_display = img_l[0, ..., 0] * 255  \n",
    "        \n",
    "        \n",
    "        pred_ab = model.predict(img_l, verbose=0)[0] \n",
    "        pred_ab = (pred_ab + 1) * 128 \n",
    "        \n",
    "        \n",
    "        img_lab = np.zeros((224, 224, 3), dtype=np.float32)\n",
    "        img_lab[:, :, 0] = img_l_display\n",
    "        img_lab[:, :, 1:] = pred_ab\n",
    "        \n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img_lab.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        \n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.title(\"Grayscale (L)\")\n",
    "        plt.imshow(img_l_display, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        \n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.title(\"Predicted Color\")\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        \n",
    "        if y_test is not None:\n",
    "            img_ab_true = (y_test[idx] + 1) * 128  \n",
    "            img_lab_true = np.zeros((224, 224, 3), dtype=np.float32)\n",
    "            img_lab_true[:, :, 0] = img_l_display\n",
    "            img_lab_true[:, :, 1:] = img_ab_true\n",
    "            img_rgb_true = cv2.cvtColor(img_lab_true.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "            \n",
    "            plt.subplot(num_images, 3, i * 3 + 3)\n",
    "            plt.title(\"Ground Truth\")\n",
    "            plt.imshow(img_rgb_true)\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9210675-3fae-4fbd-90c2-ff08a6be6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for imgdir in os.listdir(DATA_PATH):\n",
    "    img = cv2.imread(DATA_PATH + imgdir)\n",
    "    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img_lab_rs = cv2.resize(img_lab,IMG_DIM)\n",
    "    img_l = img_lab_rs[:,:,0]\n",
    "    img_ab = img_lab_rs[:,:,1:] \n",
    "    X.append(img_l[...,np.newaxis]) # [...,np.newaxis] sprawia Å¼e mamy tensor (128,128,1) a nie (128,128)\n",
    "    y.append(img_ab)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X /255\n",
    "y = y / 128 -1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fb41c-6933-4467-a45d-c8d6e8ede1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(X, y,test_size=0.2)\n",
    "input_shape = X_train[0].shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaced15c-1a89-46ad-a072-d5ab75fc520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.InputLayer(shape=input_shape),\n",
    "\n",
    "    \n",
    "  layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, kernel_initializer='he_uniform'),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=2, kernel_initializer='he_uniform'),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "   \n",
    "    layers.Conv2DTranspose(64, (4, 4), strides=2, activation='relu', padding='same', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_uniform'),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    layers.Conv2DTranspose(32, (4, 4), strides=2, activation='relu', padding='same', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_uniform'),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    layers.Conv2D(2, (3, 3), activation='tanh', padding='same', kernel_initializer='he_uniform'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe442d6b-1e00-40d5-ae0a-21b3d9c2db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ef69c-02b5-43ed-9fa3-9ef2c1fe020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19105c-e7a2-48fe-aa4a-3712a1530087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train, batch_size=32, augmentation=True)\n",
    "val_ds = create_dataset(X_test, y_test, batch_size=32, augmentation=False)\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "                   verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
